{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "8de423ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import re\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1444d38d",
   "metadata": {},
   "outputs": [],
   "source": [
    "from extract_dataframe import read_json         # a function to load json_data \n",
    "from extract_dataframe import TweetDfExtractor  # and a class to extract relevant variables.    \n",
    "from clean_tweets_dataframe import Clean_Tweets        # collection of functions to for cleaning the dataframe.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72505847",
   "metadata": {},
   "source": [
    "load json "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e347e2c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25cc8b24",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1bf5fba",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "16 columns passed, passed data had 17 columns",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    885\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 886\u001b[1;33m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_validate_or_indexify_columns\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    887\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_validate_or_indexify_columns\u001b[1;34m(content, columns)\u001b[0m\n\u001b[0;32m    933\u001b[0m             \u001b[1;31m# caller's responsibility to check for this...\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 934\u001b[1;33m             raise AssertionError(\n\u001b[0m\u001b[0;32m    935\u001b[0m                 \u001b[1;34mf\"{len(columns)} columns passed, passed data had \"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAssertionError\u001b[0m: 16 columns passed, passed data had 17 columns",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp/ipykernel_25152/2177633691.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[0m_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtweet_list\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mread_json\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"data/africa_twitter_data.json\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[0mtweet\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mTweetDfExtractor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtweet_list\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mtweet\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_tweet_df\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# this will also generate a CSV file.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      4\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"Please, load the CSV file\"\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\10_20\\Twitter-Data-Analysis\\extract_dataframe.py\u001b[0m in \u001b[0;36mget_tweet_df\u001b[1;34m(self, save)\u001b[0m\n\u001b[0;32m    189\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    190\u001b[0m         \u001b[0mdata\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcreated_at\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msource\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtext\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mu_text\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpolarity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msubjectivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlang\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfav_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mretweet_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscreen_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morginal_author\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfollower_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfriends_count\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msensitivity\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mhashtags\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmentions\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlocation\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 191\u001b[1;33m         \u001b[0mdf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    192\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    193\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0msave\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\frame.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    692\u001b[0m                         \u001b[1;31m# ndarray], Index, Series], Sequence[Any]]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    693\u001b[0m                         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# type: ignore[arg-type]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 694\u001b[1;33m                     arrays, columns, index = nested_data_to_arrays(\n\u001b[0m\u001b[0;32m    695\u001b[0m                         \u001b[1;31m# error: Argument 3 to \"nested_data_to_arrays\" has incompatible\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    696\u001b[0m                         \u001b[1;31m# type \"Optional[Collection[Any]]\"; expected \"Optional[Index]\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mnested_data_to_arrays\u001b[1;34m(data, columns, index, dtype)\u001b[0m\n\u001b[0;32m    479\u001b[0m         \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_fields\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    480\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 481\u001b[1;33m     \u001b[0marrays\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mto_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    482\u001b[0m     \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mensure_index\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolumns\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    483\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36mto_arrays\u001b[1;34m(data, columns, dtype)\u001b[0m\n\u001b[0;32m    785\u001b[0m         \u001b[0marr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_list_to_arrays\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    786\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 787\u001b[1;33m     \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_finalize_columns_and_data\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0marr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    788\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcontent\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolumns\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\envs\\thesis\\lib\\site-packages\\pandas\\core\\internals\\construction.py\u001b[0m in \u001b[0;36m_finalize_columns_and_data\u001b[1;34m(content, columns, dtype)\u001b[0m\n\u001b[0;32m    887\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mAssertionError\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    888\u001b[0m         \u001b[1;31m# GH#26429 do not raise user-facing AssertionError\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 889\u001b[1;33m         \u001b[1;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0merr\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[0merr\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    890\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    891\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcontents\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mcontents\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdtype\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mobject_\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: 16 columns passed, passed data had 17 columns"
     ]
    }
   ],
   "source": [
    "_, tweet_list = read_json(\"data/africa_twitter_data.json\")\n",
    "tweet = TweetDfExtractor(tweet_list)\n",
    "tweet.get_tweet_df(True)  # this will also generate a CSV file.\n",
    "print(\"Please, load the CSV file\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "027ea9da",
   "metadata": {},
   "source": [
    "Load the CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a645b083",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c74dc534",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df = pd.read_csv('processed_tweet_data.csv')  # loads the csv file created above.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74664a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "977b5866",
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00480a52",
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaner = Clean_Tweets(tweet_df)\n",
    "tweet_df = cleaner.drop_unwanted_column(tweet_df)\n",
    "tweet_df = cleaner.drop_duplicate(tweet_df)\n",
    "tweet_df = cleaner.convert_to_datetime(tweet_df)\n",
    "tweet_df = cleaner.convert_to_numbers(tweet_df)\n",
    "clean_tweet_df = cleaner.remove_non_english_tweets(tweet_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "775c8321",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0d61cc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_tweet_df.describe() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2beecb8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# selecting only the relevant variables for further analysis\n",
    "sho_tweet_df = clean_tweet_df.drop(['original_text', 'user_mentions', 'possibly_sensitive'], axis=1)\n",
    "loc_tweet_df = sho_tweet_df.dropna() # droping rows with null values\n",
    "\n",
    "#resetting indexes\n",
    "sho_tweet_df = sho_tweet_df.reset_index();\n",
    "sho_tweet_df = sho_tweet_df.drop(columns=['index'])\n",
    "\n",
    "loc_tweet_df = loc_tweet_df.reset_index();\n",
    "loc_tweet_df = loc_tweet_df.drop(columns=['index'])\n",
    "\n",
    "print(clean_tweet_df.shape)\n",
    "print(sho_tweet_df.shape)\n",
    "print(loc_tweet_df.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2dd91110",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_group (p): \n",
    "    if p > 0:\n",
    "        return 'positive'\n",
    "    elif p < 0:\n",
    "        return 'negative'\n",
    "    else:\n",
    "        return 'neutral'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4661917",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentiment = pd.Series([sentiment_group(row_val) for row_val in list(loc_tweet_df['polarity'])])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e74246a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sho_tweet_df = pd.concat([sho_tweet_df, sentiment.rename(\"sentiment\")], axis=1)\n",
    "loc_tweet_df = pd.concat([loc_tweet_df, sentiment.rename(\"sentiment\")], axis=1)\n",
    "\n",
    "sho_tweet_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5dd86e9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aeb4ad1d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2218359b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "a64e837968ba76e94c56c9b4d5fd774eaa292be1ba63723c587f1d17b7450a36"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
